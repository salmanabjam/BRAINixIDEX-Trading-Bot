"""
BiX TradeBOT - Fundamental News Analyzer
========================================
Ø¯Ø±ÛŒØ§ÙØª Ùˆ ØªØ­Ù„ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„ Ø§Ø² TradingView Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„

Author: SALMAN ThinkTank AI Core
Version: 2.0.0
"""

import requests
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import time

logger = logging.getLogger(__name__)


class FundamentalNewsAnalyzer:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ùˆ ØªØ­Ù„ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„ Ø§Ø² TradingView
    
    Features:
    - Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø± Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Ù…Ù†Ø¨Ø¹ TradingView
    - ØªØ­Ù„ÛŒÙ„ Ø³Ù†ØªÛŒÙ…Ù†Øª Ø§Ø®Ø¨Ø§Ø± (Ù…Ø«Ø¨Øª/Ù…Ù†ÙÛŒ/Ø®Ù†Ø«ÛŒ)
    - Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¯Ø± JSON
    - Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ØªÙ…Ø§Ù… Ø§Ø±Ø²Ù‡Ø§ÛŒ Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Binance
    """

    def __init__(self, symbol: str = "BTCUSDT", exchange: str = "BINANCE"):
        """
        Initialize Fundamental News Analyzer.
        
        Args:
            symbol: Ù†Ù…Ø§Ø¯ Ø§Ø±Ø² Ø¯ÛŒØ¬ÛŒØªØ§Ù„ (Ù…Ø«Ø§Ù„: BTCUSDT, ADAUSDT, SOLUSDT)
            exchange: ØµØ±Ø§ÙÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: BINANCE)
        """
        self.symbol = symbol
        self.exchange = exchange
        self.base_symbol = symbol.replace("USDT", "").replace("BUSD", "")
        
        # Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
        self.news_dir = Path("news_data")
        self.news_dir.mkdir(exist_ok=True)
        
        # Headers Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://www.tradingview.com/'
        }
        
        logger.info(f"ğŸ“° Fundamental News Analyzer initialized for {symbol}")

    def _build_tradingview_symbol(self) -> str:
        """Ø³Ø§Ø®Øª Ù†Ù…Ø§Ø¯ TradingView"""
        return f"{self.exchange}%3A{self.symbol}"

    def fetch_news_headlines(self) -> List[Dict[str, Any]]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±Ø®Ø· Ø§Ø®Ø¨Ø§Ø± Ø§Ø² TradingView
        
        Returns:
            Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø± Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„
        """
        tv_symbol = self._build_tradingview_symbol()
        
        # Ø¯Ùˆ URL Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø®Ø¨Ø§Ø±
        urls = [
            f"https://news-headlines.tradingview.com/v2/view/headlines/symbol?client=landing&lang=en&section=&streaming=true&symbol={tv_symbol}",
            f"https://news-headlines.tradingview.com/v2/view/headlines/symbol?client=overview&lang=en&symbol={tv_symbol}"
        ]
        
        all_news = []
        
        for url in urls:
            try:
                logger.info(f"ğŸ“¥ Fetching news from: {url[:80]}...")
                response = requests.get(url, headers=self.headers, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø±
                    if isinstance(data, dict) and 'items' in data:
                        news_items = data['items']
                    elif isinstance(data, list):
                        news_items = data
                    else:
                        news_items = []
                    
                    for item in news_items:
                        news_entry = self._parse_news_item(item)
                        if news_entry and news_entry not in all_news:
                            all_news.append(news_entry)
                    
                    logger.info(f"âœ… Fetched {len(news_items)} news from this source")
                else:
                    logger.warning(f"âš ï¸ HTTP {response.status_code} for {url[:50]}")
                    
            except Exception as e:
                logger.error(f"âŒ Error fetching from {url[:50]}: {e}")
            
            time.sleep(0.5)  # Rate limiting
        
        logger.info(f"ğŸ“Š Total unique news fetched: {len(all_news)}")
        return all_news

    def fetch_community_ideas(self) -> List[Dict[str, Any]]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† TradingView
        
        Returns:
            Ù„ÛŒØ³Øª Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ
        """
        url = f"https://www.tradingview.com/symbols/{self.symbol}/ideas/?exchange={self.exchange}&component-data-only=1"
        
        try:
            logger.info(f"ğŸ’¡ Fetching community ideas...")
            response = requests.get(url, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                ideas = []
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ (Ø³Ø§Ø®ØªØ§Ø± Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯)
                if isinstance(data, dict):
                    ideas_list = data.get('ideas', []) or data.get('data', [])
                    
                    for idea in ideas_list:
                        idea_entry = self._parse_idea_item(idea)
                        if idea_entry:
                            ideas.append(idea_entry)
                
                logger.info(f"âœ… Fetched {len(ideas)} community ideas")
                return ideas
            else:
                logger.warning(f"âš ï¸ HTTP {response.status_code} for ideas")
                return []
                
        except Exception as e:
            logger.error(f"âŒ Error fetching ideas: {e}")
            return []

    def fetch_conversation_status(self) -> Dict[str, Any]:
        """
        Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ú¯ÙØªÚ¯ÙˆÙ‡Ø§ Ùˆ Ø³Ù†ØªÛŒÙ…Ù†Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        
        Returns:
            Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø­Ø§ÙˆÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ù†ØªÛŒÙ…Ù†Øª
        """
        tv_symbol = self._build_tradingview_symbol()
        url = f"https://www.tradingview.com/conversation-status/?_rand={time.time()}&offset=0&room_id=general&stat_symbol={tv_symbol}&is_private="
        
        try:
            logger.info(f"ğŸ’¬ Fetching conversation status...")
            response = requests.get(url, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                sentiment_data = {
                    'timestamp': datetime.now().isoformat(),
                    'symbol': self.symbol,
                    'conversation_count': data.get('count', 0),
                    'active_users': data.get('active_users', 0),
                    'bullish_mentions': data.get('bullish', 0),
                    'bearish_mentions': data.get('bearish', 0),
                    'sentiment_score': self._calculate_sentiment_score(data),
                    'raw_data': data
                }
                
                logger.info(f"âœ… Conversation data fetched")
                return sentiment_data
            else:
                logger.warning(f"âš ï¸ HTTP {response.status_code} for conversation")
                return {}
                
        except Exception as e:
            logger.error(f"âŒ Error fetching conversation: {e}")
            return {}

    def _parse_news_item(self, item: Dict) -> Optional[Dict[str, Any]]:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© Ø®Ø¨Ø±"""
        try:
            return {
                'id': item.get('id', ''),
                'title': item.get('title', ''),
                'published': item.get('published', ''),
                'source': item.get('provider', {}).get('name', 'Unknown'),
                'link': item.get('link', ''),
                'shortDescription': item.get('shortDescription', ''),
                'sentiment': self._analyze_sentiment(
                    item.get('title', '') + ' ' + item.get('shortDescription', '')
                ),
                'tags': item.get('tags', []),
                'fetchedAt': datetime.now().isoformat()
            }
        except Exception as e:
            logger.debug(f"Error parsing news item: {e}")
            return None

    def _parse_idea_item(self, item: Dict) -> Optional[Dict[str, Any]]:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© Ø§ÛŒØ¯Ù‡ ØªØ­Ù„ÛŒÙ„ÛŒ"""
        try:
            return {
                'id': item.get('id', ''),
                'title': item.get('title', ''),
                'author': item.get('author', {}).get('username', 'Unknown'),
                'imageUrl': item.get('imageUrl', ''),
                'description': item.get('description', ''),
                'likes': item.get('agree', 0),
                'comments': item.get('comments_count', 0),
                'isLong': item.get('is_long', None),
                'isShort': item.get('is_short', None),
                'publishedAt': item.get('publishedAt', ''),
                'sentiment': 'bullish' if item.get('is_long') else ('bearish' if item.get('is_short') else 'neutral'),
                'fetchedAt': datetime.now().isoformat()
            }
        except Exception as e:
            logger.debug(f"Error parsing idea item: {e}")
            return None

    def _analyze_sentiment(self, text: str) -> str:
        """
        ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ø³Ù†ØªÛŒÙ…Ù†Øª Ù…ØªÙ†
        
        Args:
            text: Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
            
        Returns:
            'bullish', 'bearish', ÛŒØ§ 'neutral'
        """
        text_lower = text.lower()
        
        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø«Ø¨Øª
        bullish_keywords = [
            'bullish', 'buy', 'long', 'surge', 'rally', 'gain', 'rise',
            'breakout', 'moon', 'pump', 'bull', 'growth', 'profit',
            'upgrade', 'partnership', 'adoption', 'positive'
        ]
        
        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ù†ÙÛŒ
        bearish_keywords = [
            'bearish', 'sell', 'short', 'crash', 'dump', 'fall', 'drop',
            'breakdown', 'bear', 'loss', 'decline', 'downgrade',
            'risk', 'concern', 'negative', 'plunge'
        ]
        
        bullish_count = sum(1 for word in bullish_keywords if word in text_lower)
        bearish_count = sum(1 for word in bearish_keywords if word in text_lower)
        
        if bullish_count > bearish_count:
            return 'bullish'
        elif bearish_count > bullish_count:
            return 'bearish'
        else:
            return 'neutral'

    def _calculate_sentiment_score(self, data: Dict) -> float:
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø³Ù†ØªÛŒÙ…Ù†Øª (-1 ØªØ§ +1)
        
        Args:
            data: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯ÙØªÚ¯Ùˆ
            
        Returns:
            Ø§Ù…ØªÛŒØ§Ø² Ø³Ù†ØªÛŒÙ…Ù†Øª
        """
        bullish = data.get('bullish', 0)
        bearish = data.get('bearish', 0)
        total = bullish + bearish
        
        if total == 0:
            return 0.0
        
        return (bullish - bearish) / total

    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """
        ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹ Ø§Ø®Ø¨Ø§Ø± ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„
        
        Returns:
            Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§ ØªÙ…Ø§Ù… Ø§Ø·Ù„Ø§Ø¹Ø§Øª
        """
        logger.info(f"ğŸ“Š Generating comprehensive fundamental report for {self.symbol}...")
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        news = self.fetch_news_headlines()
        ideas = self.fetch_community_ideas()
        conversation = self.fetch_conversation_status()
        
        # ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ Ø³Ù†ØªÛŒÙ…Ù†Øª
        overall_sentiment = self._calculate_overall_sentiment(news, ideas, conversation)
        
        # Ø³Ø§Ø®Øª Ú¯Ø²Ø§Ø±Ø´
        report = {
            'metadata': {
                'symbol': self.symbol,
                'exchange': self.exchange,
                'base_currency': self.base_symbol,
                'generated_at': datetime.now().isoformat(),
                'timezone': 'UTC'
            },
            'news_headlines': {
                'total_count': len(news),
                'items': news,
                'sources': list(set([n['source'] for n in news if 'source' in n])),
                'sentiment_breakdown': self._sentiment_breakdown(news)
            },
            'community_ideas': {
                'total_count': len(ideas),
                'items': ideas,
                'sentiment_breakdown': self._sentiment_breakdown(ideas)
            },
            'conversation_status': conversation,
            'overall_analysis': {
                'sentiment': overall_sentiment['sentiment'],
                'sentiment_score': overall_sentiment['score'],
                'confidence': overall_sentiment['confidence'],
                'recommendation': overall_sentiment['recommendation'],
                'key_factors': overall_sentiment['factors']
            },
            'statistics': {
                'total_news': len(news),
                'total_ideas': len(ideas),
                'bullish_signals': overall_sentiment['bullish_count'],
                'bearish_signals': overall_sentiment['bearish_count'],
                'neutral_signals': overall_sentiment['neutral_count']
            }
        }
        
        logger.info(f"âœ… Report generated: {overall_sentiment['sentiment'].upper()} sentiment")
        return report

    def _sentiment_breakdown(self, items: List[Dict]) -> Dict[str, int]:
        """ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹ Ø³Ù†ØªÛŒÙ…Ù†Øª"""
        breakdown = {'bullish': 0, 'bearish': 0, 'neutral': 0}
        
        for item in items:
            sentiment = item.get('sentiment', 'neutral')
            if sentiment in breakdown:
                breakdown[sentiment] += 1
        
        return breakdown

    def _calculate_overall_sentiment(
        self, 
        news: List[Dict], 
        ideas: List[Dict], 
        conversation: Dict
    ) -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ù†ØªÛŒÙ…Ù†Øª Ú©Ù„ÛŒ Ø¨Ø§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ"""
        
        # Ø´Ù…Ø§Ø±Ø´ Ø³Ù†ØªÛŒÙ…Ù†Øªâ€ŒÙ‡Ø§
        bullish = 0
        bearish = 0
        neutral = 0
        
        # ÙˆØ²Ù† Ø§Ø®Ø¨Ø§Ø± (40%)
        for item in news:
            sentiment = item.get('sentiment', 'neutral')
            if sentiment == 'bullish':
                bullish += 0.4
            elif sentiment == 'bearish':
                bearish += 0.4
            else:
                neutral += 0.4
        
        # ÙˆØ²Ù† Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ (40%)
        for item in ideas:
            sentiment = item.get('sentiment', 'neutral')
            if sentiment == 'bullish':
                bullish += 0.4
            elif sentiment == 'bearish':
                bearish += 0.4
            else:
                neutral += 0.4
        
        # ÙˆØ²Ù† Ú¯ÙØªÚ¯ÙˆÙ‡Ø§ (20%)
        conv_score = conversation.get('sentiment_score', 0)
        if conv_score > 0.2:
            bullish += 0.2
        elif conv_score < -0.2:
            bearish += 0.2
        else:
            neutral += 0.2
        
        total = bullish + bearish + neutral
        
        if total == 0:
            return {
                'sentiment': 'neutral',
                'score': 0.0,
                'confidence': 0.0,
                'recommendation': 'HOLD - Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª',
                'factors': [],
                'bullish_count': 0,
                'bearish_count': 0,
                'neutral_count': 0
            }
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
        bullish_pct = bullish / total
        bearish_pct = bearish / total
        neutral_pct = neutral / total
        
        # ØªØ¹ÛŒÛŒÙ† Ø³Ù†ØªÛŒÙ…Ù†Øª ØºØ§Ù„Ø¨
        if bullish_pct > 0.5:
            sentiment = 'bullish'
            score = bullish_pct - bearish_pct
            recommendation = 'BUY - Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø«Ø¨Øª Ù‚ÙˆÛŒ'
        elif bearish_pct > 0.5:
            sentiment = 'bearish'
            score = bearish_pct - bullish_pct
            recommendation = 'SELL - Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ù†ÙÛŒ Ù‚ÙˆÛŒ'
        elif abs(bullish_pct - bearish_pct) < 0.2:
            sentiment = 'neutral'
            score = 0.0
            recommendation = 'HOLD - Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†Ø§Ù‚Ø¶'
        else:
            sentiment = 'neutral'
            score = bullish_pct - bearish_pct
            recommendation = 'HOLD - Ø¹Ø¯Ù… Ø§Ø·Ù…ÛŒÙ†Ø§Ù†'
        
        # Ø¹ÙˆØ§Ù…Ù„ Ú©Ù„ÛŒØ¯ÛŒ
        factors = []
        if len(news) > 5:
            factors.append(f"{len(news)} Ø®Ø¨Ø± ØªØ§Ø²Ù‡ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡")
        if len(ideas) > 3:
            factors.append(f"{len(ideas)} ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†")
        if conversation.get('conversation_count', 0) > 10:
            factors.append(f"{conversation.get('conversation_count')} Ú¯ÙØªÚ¯ÙˆÛŒ ÙØ¹Ø§Ù„")
        
        confidence = min(0.95, (len(news) + len(ideas)) / 20)
        
        return {
            'sentiment': sentiment,
            'score': round(score, 3),
            'confidence': round(confidence, 2),
            'recommendation': recommendation,
            'factors': factors,
            'bullish_count': int(bullish),
            'bearish_count': int(bearish),
            'neutral_count': int(neutral)
        }

    def save_report_to_json(self, report: Dict[str, Any]) -> str:
        """
        Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± ÙØ§ÛŒÙ„ JSON
        
        Args:
            report: Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„
            
        Returns:
            Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.symbol}_{timestamp}_fundamental.json"
        filepath = self.news_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ Report saved to: {filepath}")
        return str(filepath)

    def get_latest_report(self) -> Optional[Dict[str, Any]]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡"""
        try:
            json_files = list(self.news_dir.glob(f"{self.symbol}_*_fundamental.json"))
            if not json_files:
                return None
            
            latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"âŒ Error loading report: {e}")
            return None


def main():
    """ØªØ³Øª Ø³ÛŒØ³ØªÙ… Ø§Ø®Ø¨Ø§Ø± ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„"""
    
    # Ù…Ø«Ø§Ù„ 1: ADA
    print("\n" + "="*60)
    print("ğŸ“° Testing Fundamental News for ADAUSDT")
    print("="*60)
    
    analyzer = FundamentalNewsAnalyzer("ADAUSDT")
    report = analyzer.generate_comprehensive_report()
    filepath = analyzer.save_report_to_json(report)
    
    print(f"\nâœ… Report saved: {filepath}")
    print(f"ğŸ“Š Sentiment: {report['overall_analysis']['sentiment'].upper()}")
    print(f"ğŸ’¯ Confidence: {report['overall_analysis']['confidence']*100:.1f}%")
    print(f"ğŸ“ˆ Recommendation: {report['overall_analysis']['recommendation']}")
    
    # Ù…Ø«Ø§Ù„ 2: SOL
    print("\n" + "="*60)
    print("ğŸ“° Testing Fundamental News for SOLUSDT")
    print("="*60)
    
    analyzer_sol = FundamentalNewsAnalyzer("SOLUSDT")
    report_sol = analyzer_sol.generate_comprehensive_report()
    filepath_sol = analyzer_sol.save_report_to_json(report_sol)
    
    print(f"\nâœ… Report saved: {filepath_sol}")
    print(f"ğŸ“Š Sentiment: {report_sol['overall_analysis']['sentiment'].upper()}")
    print(f"ğŸ’¯ Confidence: {report_sol['overall_analysis']['confidence']*100:.1f}%")
    print(f"ğŸ“ˆ Recommendation: {report_sol['overall_analysis']['recommendation']}")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    main()
